{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8110fc71",
   "metadata": {
    "problem_id": "ex1"
   },
   "source": [
    "#### Exercise 1\n",
    "<!-- @q -->\n",
    "\n",
    "1. What kinds of EDA techniques might you use to explore the following types of data:\n",
    "    - Numeric data?  \n",
    "    With numeric data, I might use a dunction like `describe()` to produce summary statistics on any and all variables I plan to use (exclude row counts, etc.). I'll also want to inspect the distribution of my target variable(s) using a histogram.\n",
    "    - Categorical data?  \n",
    "    Similarly, I will want to get a feel for the categorical data. I can use barplots to inspect the distribution, and run summary statistics to understand the mode(s) and uncover any ranked variables.\n",
    "    - The relationship between categorical and numeric data?\n",
    "    If we're just running EDA, the approach would simply be to inspect the numeric data in its own way and the categprical in its own. One should also look at encoding the variables into numeric bins, or other ways to get them to interact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813b98cf",
   "metadata": {
    "part_id": "ex1-part1",
    "span": "ex1-part1.answer",
    "student": true
   },
   "source": [
    "*Enter your answer in this cell*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5af7624",
   "metadata": {
    "part_id": "ex1-part2"
   },
   "source": [
    "2. Generate some fake data (~1000 rows) with 1 categorical column (with 10 categories) and 2 numeric columns. Use the techniques you mentioned to explore the numeric, categorical, and the relationship between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b78018a6",
   "metadata": {
    "additional_cells_expected": true,
    "part_id": "ex1-part2",
    "span": "ex1-part2.code",
    "student": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "import random\n",
    "import pandas as pd\n",
    "one_to_ten = [random.randint(1, 10) for i in range(1000)]\n",
    "two_to_twelve = [random.randint(2, 12) for i in range(1000)]\n",
    "colors = ['red', 'orange', 'yellow', 'green', 'blue', 'indigo', 'violet', 'white', 'black', 'gold']\n",
    "colors_list = [random.choice(colors) for i in range(1000)]\n",
    "df = pd.DataFrame({\n",
    "    \"one_to_ten\": one_to_ten,\n",
    "    \"two_to_twelve\": two_to_twelve,\n",
    "    \"colors\": colors_list\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9bdce91",
   "metadata": {
    "additional_cells_expected": true,
    "part_id": "ex1-part2",
    "span": "ex1-part2.code",
    "student": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one_to_ten</th>\n",
       "      <th>two_to_twelve</th>\n",
       "      <th>colors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>violet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   one_to_ten  two_to_twelve  colors\n",
       "0           3              9    blue\n",
       "1          10              7  violet\n",
       "2          10              3   green\n",
       "3           9             10  orange\n",
       "4           1              9   white"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d32a8118",
   "metadata": {
    "additional_cells_expected": true,
    "part_id": "ex1-part2",
    "span": "ex1-part2.code",
    "student": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one_to_ten</th>\n",
       "      <th>two_to_twelve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.433000</td>\n",
       "      <td>6.663000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.911011</td>\n",
       "      <td>3.156802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        one_to_ten  two_to_twelve\n",
       "count  1000.000000    1000.000000\n",
       "mean      5.433000       6.663000\n",
       "std       2.911011       3.156802\n",
       "min       1.000000       2.000000\n",
       "25%       3.000000       4.000000\n",
       "50%       5.000000       7.000000\n",
       "75%       8.000000       9.000000\n",
       "max      10.000000      12.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89d6dab1",
   "metadata": {
    "additional_cells_expected": true,
    "part_id": "ex1-part2",
    "span": "ex1-part2.code",
    "student": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "colors\n",
       "violet    108\n",
       "white     108\n",
       "yellow    108\n",
       "black     105\n",
       "blue       99\n",
       "indigo     99\n",
       "red        98\n",
       "gold       95\n",
       "green      93\n",
       "orange     87\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "df['colors'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df5799fe",
   "metadata": {
    "additional_cells_expected": true,
    "part_id": "ex1-part2",
    "span": "ex1-part2.code",
    "student": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one_to_ten</th>\n",
       "      <th>two_to_twelve</th>\n",
       "      <th>colors</th>\n",
       "      <th>colors_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>blue</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>violet</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>green</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>orange</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>white</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   one_to_ten  two_to_twelve  colors  colors_encoded\n",
       "0           3              9    blue               1\n",
       "1          10              7  violet               7\n",
       "2          10              3   green               3\n",
       "3           9             10  orange               5\n",
       "4           1              9   white               8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "df[\"colors_encoded\"] = df[\"colors\"].astype(\"category\").cat.codes\n",
    "#Code from ChatGPT for .cat and .codes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dfb53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean        4.579000\n",
       "std         2.931954\n",
       "min         0.000000\n",
       "25%         2.000000\n",
       "50%         5.000000\n",
       "75%         7.000000\n",
       "max         9.000000\n",
       "Name: colors_encoded, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['colors_encoded'].describe()\n",
    "#If my colors variable was ranked or something"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25320be1",
   "metadata": {
    "problem_id": "2"
   },
   "source": [
    "#### Exercise 2\n",
    "\n",
    "\n",
    "Generate a data set you can use with a supervised ML model.  The data should meet the following criteria:\n",
    "   - It should have 1000 rows\n",
    "   - It should have 6 columns, with one column (your \"target\" column being a boolean column), one categorical column with 5 categories, and 4 numeric columns.\n",
    "   - The numeric columns should have dramatically different scales - different means, different std. deviations.\n",
    "   - Each non-target column should have about 5% nulls.\n",
    "\n",
    "Make this data a little more interesting by calculating the target column using a noisy function of the other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a941ebec",
   "metadata": {
    "additional_cells_expected": true,
    "part_id": "2-part1",
    "span": "2-part1.code",
    "student": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   target  category       num1        num2         num3      num4\n",
      "0       0  cortland        NaN  426.252585  2558.128402  1.040625\n",
      "1       1   colgate        NaN  572.988808   277.922537  0.873543\n",
      "2       0   colgate   8.414419  436.367895   211.262391  0.952254\n",
      "3       0  cortland  10.880240         NaN -1305.948431  1.163166\n",
      "4       0  cortland   9.662175  477.079163  -326.668827  0.927046\n",
      "target      0.00\n",
      "category    0.05\n",
      "num1        0.05\n",
      "num2        0.05\n",
      "num3        0.05\n",
      "num4        0.05\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "num1 = np.random.normal(loc=10, scale=2, size=1000)\n",
    "num2 = np.random.normal(loc=500, scale=50, size=1000)\n",
    "num3 = np.random.normal(loc=1000, scale=2000, size=1000)\n",
    "num4 = np.random.normal(loc=1, scale=.1, size=1000)\n",
    "\n",
    "# categorical (5 levels) â€” note: no extra brackets\n",
    "colleges = ['syracuse', 'buffalo', 'binghamton', 'cortland', 'colgate']\n",
    "cat_col = np.random.choice(colleges, 1000)\n",
    "\n",
    "# noisy target = function(num1..4, category) + noise, threshold at 0\n",
    "cat_weights = {'syracuse':0.6,'buffalo':0.2,'binghamton':0.0,'cortland':-0.2,'colgate':-0.4}\n",
    "signal = (0.5*num1 + 0.01*num2 - 0.00005*num3 + 2*num4\n",
    "          + np.vectorize(cat_weights.get)(cat_col))\n",
    "score = signal + np.random.normal(0,1,1000)\n",
    "target = (score > np.median(score)).astype(int)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'target': target,\n",
    "    'category': cat_col,\n",
    "    'num1': num1, 'num2': num2, 'num3': num3, 'num4': num4\n",
    "})\n",
    "\n",
    "# null adder taken from internet\n",
    "for c in ['category','num1','num2','num3','num4']:\n",
    "    idx = np.random.choice(df.index, int(0.05*1000), replace=False)\n",
    "    df.loc[idx, c] = np.nan\n",
    "\n",
    "print(df.head())\n",
    "print(df.isna().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53678de6",
   "metadata": {
    "problem_id": "ex2"
   },
   "source": [
    "#### Exercise 3\n",
    "\n",
    "Use whatever resources you need to figure out how to build an SKLearn ML pipelines. Use a pipeline to build an ML approach to predicting your target column in the preceding data with logistic regression.  I have set up the problem below so that you will write your code in a function function call that takes an SKLearn model and data frame and returns the results of a cross validation scoring routine.  \n",
    "\n",
    "I have not taught you how to do this; use the book, google, the notes, chatgpt, or whatever. This is a test of your ability to *find* information, and use this to construct a solution. Your solution should:\n",
    "\n",
    "- Use a transformer pipeline that processes your numeric and categorical features separately\n",
    "- Place everything in a pipeline with the classifier that is passed in to the function.\n",
    "- I've already implemented the call to cross_val_score - to make it work, you'll need to assign your pipeline to the `pipeline` variable.\n",
    "\n",
    "_Note: You could just feed this question to AI and get an answer, and chances are, it will be right. But if you do, you won't really learn much. So, be thoughtful in your use of AI here - you can use it to build the solution step by step, and it will explain how everything works. It's all in how you use it. So, it's your choice - go for the easy grade, or learn something._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4bd23a7",
   "metadata": {
    "part_id": "ex2-part1",
    "span": "ex2-part1.fill",
    "student": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 (5-fold): mean=0.770, std=0.021\n",
      "Fold scores: [0.738 0.778 0.77  0.761 0.802]\n"
     ]
    }
   ],
   "source": [
    "# --- Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def run_classifier(df,classifier):\n",
    "    # Separate features/target\n",
    "    y = df[\"target\"].astype(int)  # this is redundant? eh why not\n",
    "    X = df.drop(columns=[\"target\"])\n",
    "\n",
    "    #You fill in the pipeline definition.  Make sure to:\n",
    "    # - process categorical features (using an imputer and one hot encoder)\n",
    "    # - process numeric features (using an imputer and StandardScaler)\n",
    "    # - define your pipeline using `pipeline = ...`\n",
    "    \n",
    "    num_cols = [\"num1\", \"num2\", \"num3\", \"num4\"]\n",
    "    cat_cols = [\"category\"]\n",
    "\n",
    "    num_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ])\n",
    "    cat_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        (\"num\", num_transformer, num_cols),\n",
    "        (\"cat\", cat_transformer, cat_cols),\n",
    "    ])\n",
    "\n",
    "    pipeline = Pipeline(steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"clf\", classifier),\n",
    "    ]) \n",
    "\n",
    "    # --- 5-fold CV using F1\n",
    "    return cross_val_score(pipeline, X, y, scoring=\"f1\", cv=5)\n",
    "\n",
    "\n",
    "scores = run_classifier(df,LogisticRegression(random_state=42))\n",
    "print(f\"F1 (5-fold): mean={scores.mean():.3f}, std={scores.std():.3f}\")\n",
    "print(\"Fold scores:\", np.round(scores, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f06eb0b",
   "metadata": {
    "part_id": "ex2-part2"
   },
   "source": [
    "Try using a `RandomForestClassifier` in the preceding pipeline. Just call `run_classifier` with a `RandomForestClassifier`, and print out the results as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a65de74c",
   "metadata": {
    "part_id": "ex2-part2",
    "span": "ex2-part2.code",
    "student": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 (5-fold): mean=0.749, std=0.025\n",
      "Fold scores: [0.704 0.771 0.759 0.738 0.772]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "scores = run_classifier(df, RandomForestClassifier(random_state=42))\n",
    "print(f\"F1 (5-fold): mean={scores.mean():.3f}, std={scores.std():.3f}\")\n",
    "print(\"Fold scores:\", np.round(scores, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bbb3b1",
   "metadata": {
    "part_id": "ex2-part3"
   },
   "source": [
    "Normally, `RandomForestClassifier`s are considered to be more powerful than `LogisticRegression`.  Depending on your data, this may or may not be the case. Reflect on your answers - which one does better here, and why do you think that is?  Once again, you might use AI, but you should probably also try to _understand_ the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb72f7e",
   "metadata": {
    "part_id": "ex2-part3",
    "span": "ex2-part3.answer",
    "student": true
   },
   "source": [
    "In this case, the LogisticRegression performs better, despite being the weaker model. If I understand correctly, we put ver simple, linear weights on our variables, which the logistic regression was able to easier detect, and the randomforest likely overcomplicated things. Although I though tree-based was supposed to perform better with categorical and numeric combo models? idk lol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6930fa5d",
   "metadata": {},
   "source": [
    "Side note: as i was doing the assignment, I was really confused why the pipelines were useful. I'm used to R and just transforming my dataframe and maybe even making a copy. There are pipelines there, but functionally different. I think after the full assignment, I understand the appeal a little better, especially if the datasets are especially large or you dont want to mess with the underlying data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
